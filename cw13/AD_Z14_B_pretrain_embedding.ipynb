{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 10:15:48.576836: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import History\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "# Zad. \n",
    "Podążamy za stroną: \n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "mamy jakiś zbiór tekstów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do warstwy **Embedding layer** wchodzi sekwencja intów.\n",
    "\n",
    "* my wykorzystamy reprezenatację Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 15], [48, 27], [30, 4], [8, 27], [49], [22], [30, 4], [5, 48], [30, 27], [16, 40, 15, 8]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 15  0  0]\n",
      " [48 27  0  0]\n",
      " [30  4  0  0]\n",
      " [ 8 27  0  0]\n",
      " [49  0  0  0]\n",
      " [22  0  0  0]\n",
      " [30  4  0  0]\n",
      " [ 5 48  0  0]\n",
      " [30 27  0  0]\n",
      " [16 40 15  8]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Embeding ma rakres 50 i długość wejściową 4. Zmniejszmy embending do wymiaru 8.\n",
    "* Model jest prostym klasyfikatorem binarnym. \n",
    "* Co ważne, wynik z warstwy Embeding będzie wynosił 4 wektory o 8 wymiarach każdy, po jednym dla każdego słowa. \n",
    "* Spłaszczamy to do jednego 32-elementowego wektora, aby przejść do warstwy wyjściowej Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433 (1.69 KB)\n",
      "Trainable params: 433 (1.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "history_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.6884 - accuracy: 0.5556 - val_loss: 0.7015 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6873 - accuracy: 0.5556 - val_loss: 0.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6861 - accuracy: 0.5556 - val_loss: 0.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6849 - accuracy: 0.5556 - val_loss: 0.7013 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6838 - accuracy: 0.5556 - val_loss: 0.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6826 - accuracy: 0.5556 - val_loss: 0.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6814 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6803 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6791 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6779 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6768 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6756 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6745 - accuracy: 0.5556 - val_loss: 0.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6733 - accuracy: 0.5556 - val_loss: 0.7013 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6721 - accuracy: 0.5556 - val_loss: 0.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6710 - accuracy: 0.5556 - val_loss: 0.7015 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6698 - accuracy: 0.5556 - val_loss: 0.7017 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6686 - accuracy: 0.5556 - val_loss: 0.7019 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6674 - accuracy: 0.5556 - val_loss: 0.7022 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6663 - accuracy: 0.5556 - val_loss: 0.7024 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6651 - accuracy: 0.5556 - val_loss: 0.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6639 - accuracy: 0.5556 - val_loss: 0.7030 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6627 - accuracy: 0.5556 - val_loss: 0.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6615 - accuracy: 0.5556 - val_loss: 0.7036 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6603 - accuracy: 0.5556 - val_loss: 0.7040 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6591 - accuracy: 0.5556 - val_loss: 0.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6579 - accuracy: 0.5556 - val_loss: 0.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6567 - accuracy: 0.5556 - val_loss: 0.7050 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6555 - accuracy: 0.5556 - val_loss: 0.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6543 - accuracy: 0.5556 - val_loss: 0.7057 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6531 - accuracy: 0.5556 - val_loss: 0.7061 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6518 - accuracy: 0.5556 - val_loss: 0.7064 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6506 - accuracy: 0.5556 - val_loss: 0.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6494 - accuracy: 0.5556 - val_loss: 0.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6482 - accuracy: 0.5556 - val_loss: 0.7075 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6469 - accuracy: 0.5556 - val_loss: 0.7079 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6457 - accuracy: 0.5556 - val_loss: 0.7083 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6444 - accuracy: 0.5556 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6432 - accuracy: 0.5556 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6419 - accuracy: 0.5556 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6407 - accuracy: 0.5556 - val_loss: 0.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6394 - accuracy: 0.5556 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6381 - accuracy: 0.5556 - val_loss: 0.7104 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6369 - accuracy: 0.5556 - val_loss: 0.7107 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6356 - accuracy: 0.5556 - val_loss: 0.7111 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6343 - accuracy: 0.5556 - val_loss: 0.7114 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6330 - accuracy: 0.5556 - val_loss: 0.7117 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6317 - accuracy: 0.5556 - val_loss: 0.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6304 - accuracy: 0.5556 - val_loss: 0.7123 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6291 - accuracy: 0.5556 - val_loss: 0.7126 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6278 - accuracy: 0.5556 - val_loss: 0.7129 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6265 - accuracy: 0.5556 - val_loss: 0.7132 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6251 - accuracy: 0.5556 - val_loss: 0.7134 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6238 - accuracy: 0.5556 - val_loss: 0.7137 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6224 - accuracy: 0.5556 - val_loss: 0.7139 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6211 - accuracy: 0.5556 - val_loss: 0.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6197 - accuracy: 0.5556 - val_loss: 0.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6184 - accuracy: 0.5556 - val_loss: 0.7146 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6170 - accuracy: 0.5556 - val_loss: 0.7148 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6156 - accuracy: 0.5556 - val_loss: 0.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6142 - accuracy: 0.5556 - val_loss: 0.7152 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6129 - accuracy: 0.6667 - val_loss: 0.7153 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6115 - accuracy: 0.6667 - val_loss: 0.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6101 - accuracy: 0.6667 - val_loss: 0.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6086 - accuracy: 0.6667 - val_loss: 0.7157 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6072 - accuracy: 0.6667 - val_loss: 0.7159 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6058 - accuracy: 0.6667 - val_loss: 0.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6044 - accuracy: 0.6667 - val_loss: 0.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6029 - accuracy: 0.6667 - val_loss: 0.7161 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6015 - accuracy: 0.6667 - val_loss: 0.7162 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6000 - accuracy: 0.6667 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5986 - accuracy: 0.7778 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5971 - accuracy: 0.7778 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5956 - accuracy: 0.7778 - val_loss: 0.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5941 - accuracy: 0.7778 - val_loss: 0.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5926 - accuracy: 0.7778 - val_loss: 0.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5911 - accuracy: 0.7778 - val_loss: 0.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5896 - accuracy: 0.7778 - val_loss: 0.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5881 - accuracy: 0.7778 - val_loss: 0.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5866 - accuracy: 0.7778 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5851 - accuracy: 0.7778 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5836 - accuracy: 0.7778 - val_loss: 0.7162 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5820 - accuracy: 0.7778 - val_loss: 0.7162 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5805 - accuracy: 0.7778 - val_loss: 0.7161 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5789 - accuracy: 0.7778 - val_loss: 0.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5774 - accuracy: 0.7778 - val_loss: 0.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5758 - accuracy: 0.7778 - val_loss: 0.7159 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5743 - accuracy: 0.7778 - val_loss: 0.7158 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5727 - accuracy: 0.7778 - val_loss: 0.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5711 - accuracy: 0.7778 - val_loss: 0.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5695 - accuracy: 0.7778 - val_loss: 0.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5679 - accuracy: 0.7778 - val_loss: 0.7153 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5663 - accuracy: 0.7778 - val_loss: 0.7151 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5647 - accuracy: 0.7778 - val_loss: 0.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5631 - accuracy: 0.7778 - val_loss: 0.7148 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5615 - accuracy: 0.7778 - val_loss: 0.7146 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5599 - accuracy: 0.7778 - val_loss: 0.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5583 - accuracy: 0.7778 - val_loss: 0.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5567 - accuracy: 0.7778 - val_loss: 0.7140 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5550 - accuracy: 0.7778 - val_loss: 0.7138 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7fda48c39070>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # fit the model\n",
    "# model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.999999\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain embedding\n",
    "\n",
    "https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "* GloVe embedding data can be found at: http://nlp.stanford.edu/data/glove.6B.zip (source page: http://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* After downloading and unzipping, you will see a few files, one of which is “glove.6B.50d.txt“, which contains a 100-dimensional version of the embedding.\n",
    "\n",
    "\n",
    "Pojedyńczy plik można pobrać z tąd:\n",
    "https://www.dropbox.com/sh/tjq47ybybgnrbel/AAAVbp0UkQTAbKWVMIi5mtHpa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.6B.50d/glove.6B.50d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m embeddings_index \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# file = open(filename, encoding=\"utf8\")\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGLOVE_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mglove.6B.50d.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     13\u001B[0m         word, coefs \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(maxsplit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'glove.6B.50d/glove.6B.50d.txt'"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B.50d')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "# file = open(filename, encoding=\"utf8\")\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'i'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43membeddings_index\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mi\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'i'"
     ]
    }
   ],
   "source": [
    "embeddings_index[\"i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a Tokenizer class that can be fit on the training data, can convert text to sequences consistently by calling the texts_to_sequences() method on the Tokenizer class, and provides access to the dictionary mapping of words to integers in a word_index attribute.\n",
    "\n",
    "https://keras.io/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# create a weight matrix for words in training docs\u001B[39;00m\n\u001B[1;32m      2\u001B[0m embedding_matrix \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((vocab_size, \u001B[38;5;241m50\u001B[39m))\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m word, i \u001B[38;5;129;01min\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241m.\u001B[39mword_index\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      4\u001B[0m     embedding_vector \u001B[38;5;241m=\u001B[39m embeddings_index\u001B[38;5;241m.\u001B[39mget(word)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m embedding_vector \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that the embedding layer can be seeded with the GloVe word embedding weights. We chose the 50-dimensional version, therefore the Embedding layer must be defined with output_dim set to 50. Finally, we do not want to update the learned word weights in this model, therefore we will set the trainable attribute for the model to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 4, 50)             2500      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2701 (10.55 KB)\n",
      "Trainable params: 201 (804.00 Byte)\n",
      "Non-trainable params: 2500 (9.77 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import History\n",
    "\n",
    "history_2 = History()\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.6931 - accuracy: 0.4444 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6931 - accuracy: 0.5556 - val_loss: 0.6941 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6930 - accuracy: 0.5556 - val_loss: 0.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6930 - accuracy: 0.5556 - val_loss: 0.6951 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6929 - accuracy: 0.5556 - val_loss: 0.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6929 - accuracy: 0.5556 - val_loss: 0.6961 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6928 - accuracy: 0.5556 - val_loss: 0.6967 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6928 - accuracy: 0.5556 - val_loss: 0.6972 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6927 - accuracy: 0.5556 - val_loss: 0.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6927 - accuracy: 0.5556 - val_loss: 0.6982 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6926 - accuracy: 0.5556 - val_loss: 0.6987 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6926 - accuracy: 0.5556 - val_loss: 0.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6925 - accuracy: 0.5556 - val_loss: 0.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6924 - accuracy: 0.5556 - val_loss: 0.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6924 - accuracy: 0.5556 - val_loss: 0.7007 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6923 - accuracy: 0.5556 - val_loss: 0.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6923 - accuracy: 0.5556 - val_loss: 0.7016 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6922 - accuracy: 0.5556 - val_loss: 0.7021 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6922 - accuracy: 0.5556 - val_loss: 0.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6921 - accuracy: 0.5556 - val_loss: 0.7031 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6921 - accuracy: 0.5556 - val_loss: 0.7036 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6920 - accuracy: 0.5556 - val_loss: 0.7041 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6920 - accuracy: 0.5556 - val_loss: 0.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6919 - accuracy: 0.5556 - val_loss: 0.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6919 - accuracy: 0.5556 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6918 - accuracy: 0.5556 - val_loss: 0.7061 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6918 - accuracy: 0.5556 - val_loss: 0.7066 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6918 - accuracy: 0.5556 - val_loss: 0.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6917 - accuracy: 0.5556 - val_loss: 0.7076 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6917 - accuracy: 0.5556 - val_loss: 0.7081 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6916 - accuracy: 0.5556 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6916 - accuracy: 0.5556 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6915 - accuracy: 0.5556 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6915 - accuracy: 0.5556 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6914 - accuracy: 0.5556 - val_loss: 0.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6914 - accuracy: 0.5556 - val_loss: 0.7110 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6913 - accuracy: 0.5556 - val_loss: 0.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6913 - accuracy: 0.5556 - val_loss: 0.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6912 - accuracy: 0.5556 - val_loss: 0.7125 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6912 - accuracy: 0.5556 - val_loss: 0.7129 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6912 - accuracy: 0.5556 - val_loss: 0.7134 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6911 - accuracy: 0.5556 - val_loss: 0.7139 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6911 - accuracy: 0.5556 - val_loss: 0.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6910 - accuracy: 0.5556 - val_loss: 0.7149 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6910 - accuracy: 0.5556 - val_loss: 0.7153 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.5556 - val_loss: 0.7158 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6909 - accuracy: 0.5556 - val_loss: 0.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6909 - accuracy: 0.5556 - val_loss: 0.7168 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6908 - accuracy: 0.5556 - val_loss: 0.7172 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6908 - accuracy: 0.5556 - val_loss: 0.7177 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6907 - accuracy: 0.5556 - val_loss: 0.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6907 - accuracy: 0.5556 - val_loss: 0.7186 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6907 - accuracy: 0.5556 - val_loss: 0.7191 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6906 - accuracy: 0.5556 - val_loss: 0.7196 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6906 - accuracy: 0.5556 - val_loss: 0.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6905 - accuracy: 0.5556 - val_loss: 0.7205 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6905 - accuracy: 0.5556 - val_loss: 0.7210 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6905 - accuracy: 0.5556 - val_loss: 0.7214 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6904 - accuracy: 0.5556 - val_loss: 0.7219 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6904 - accuracy: 0.5556 - val_loss: 0.7224 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6904 - accuracy: 0.5556 - val_loss: 0.7228 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6903 - accuracy: 0.5556 - val_loss: 0.7233 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6903 - accuracy: 0.5556 - val_loss: 0.7237 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6903 - accuracy: 0.5556 - val_loss: 0.7242 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6902 - accuracy: 0.5556 - val_loss: 0.7246 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6902 - accuracy: 0.5556 - val_loss: 0.7251 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6901 - accuracy: 0.5556 - val_loss: 0.7256 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6901 - accuracy: 0.5556 - val_loss: 0.7260 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6901 - accuracy: 0.5556 - val_loss: 0.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6900 - accuracy: 0.5556 - val_loss: 0.7269 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6900 - accuracy: 0.5556 - val_loss: 0.7274 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6900 - accuracy: 0.5556 - val_loss: 0.7278 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6899 - accuracy: 0.5556 - val_loss: 0.7283 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6899 - accuracy: 0.5556 - val_loss: 0.7287 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6899 - accuracy: 0.5556 - val_loss: 0.7291 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6898 - accuracy: 0.5556 - val_loss: 0.7296 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6898 - accuracy: 0.5556 - val_loss: 0.7300 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6898 - accuracy: 0.5556 - val_loss: 0.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6897 - accuracy: 0.5556 - val_loss: 0.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6897 - accuracy: 0.5556 - val_loss: 0.7313 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6897 - accuracy: 0.5556 - val_loss: 0.7318 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6897 - accuracy: 0.5556 - val_loss: 0.7322 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6896 - accuracy: 0.5556 - val_loss: 0.7326 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6896 - accuracy: 0.5556 - val_loss: 0.7331 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6896 - accuracy: 0.5556 - val_loss: 0.7335 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6895 - accuracy: 0.5556 - val_loss: 0.7339 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6895 - accuracy: 0.5556 - val_loss: 0.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6895 - accuracy: 0.5556 - val_loss: 0.7348 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6894 - accuracy: 0.5556 - val_loss: 0.7352 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6894 - accuracy: 0.5556 - val_loss: 0.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6894 - accuracy: 0.5556 - val_loss: 0.7361 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6894 - accuracy: 0.5556 - val_loss: 0.7365 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6893 - accuracy: 0.5556 - val_loss: 0.7369 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6893 - accuracy: 0.5556 - val_loss: 0.7373 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6893 - accuracy: 0.5556 - val_loss: 0.7378 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6892 - accuracy: 0.5556 - val_loss: 0.7382 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6892 - accuracy: 0.5556 - val_loss: 0.7386 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6892 - accuracy: 0.5556 - val_loss: 0.7390 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6892 - accuracy: 0.5556 - val_loss: 0.7394 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6891 - accuracy: 0.5556 - val_loss: 0.7398 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7fda217d1430>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABG/ElEQVR4nO3de1hU1eI+8HdmYAaGyyAXQRGFEm+BoKAEHtNzIrELeakk8oSQYaaURlRaCV5SKJMvXjh5MjFPl+Ol1PyVB49NaYkEgrc8KpqKmMnNCyOoDM7s3x/GzglQBka3wPt5nv08zp6191qzROZ17bXXlgmCIICIiIhIInKpG0BEREQdG8MIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKSupG9AcRqMRv/32GxwcHCCTyaRuDhERETWDIAi4dOkSunbtCrm86fGPNhFGfvvtN3h5eUndDCIiImqB06dPo1u3bk2+3ybCiIODA4DrH8bR0VHi1hAREVFz6HQ6eHl5id/jTWkTYaT+0oyjoyPDCBERURtzqykWLZrAmpmZCW9vb9jY2CAkJAT5+fk3LZ+RkYHevXvD1tYWXl5eeOWVV3D16tWWVE1ERETtjNlhZO3atUhMTERKSgr27NmDgIAAREREoLy8vNHyn3/+OWbMmIGUlBQcPnwYK1euxNq1a/Hmm2+2uvFERETU9pkdRtLT0xEfH4+4uDj069cPy5cvh1qtRlZWVqPld+3ahSFDhuCZZ56Bt7c3RowYgejo6FuOphAREVHHYNacEb1ej8LCQsycOVPcJ5fLER4ejtzc3EaPCQsLw6effor8/HwMHjwYJ06cwJYtW/Dss882WU9tbS1qa2vF1zqd7pZtMxgMqKurM+PTELUt1tbWUCgUUjeDiMjizAojlZWVMBgMcHd3N9nv7u6OI0eONHrMM888g8rKSvzlL3+BIAi4du0aJk+efNPLNKmpqZgzZ06z21VdXY1ff/0VgiA0+xiitkYmk6Fbt26wt7eXuilERBZ12++m2b59OxYsWIB//OMfCAkJwS+//IJp06Zh3rx5mDVrVqPHzJw5E4mJieLr+luDGmMwGPDrr79CrVbDzc2Ni6JRuyQIAioqKvDrr7/C19eXIyRE1K6YFUZcXV2hUChQVlZmsr+srAweHh6NHjNr1iw8++yzeP755wEA/v7+qKmpwaRJk/DWW281uiKbSqWCSqVqVpvq6uogCALc3Nxga2trzschalPc3NxQXFyMuro6hhEialfMmsCqVCoRFBQErVYr7jMajdBqtQgNDW30mMuXLzcIHPW/SC15WYUjItTe8WeciNorsy/TJCYmYsKECQgODsbgwYORkZGBmpoaxMXFAQBiYmLg6emJ1NRUAEBkZCTS09MxYMAA8TLNrFmzEBkZyf/dERERkflhJCoqChUVFUhOTkZpaSkCAwORnZ0tTmotKSkxGQl5++23IZPJ8Pbbb+PMmTNwc3NDZGQk5s+fb7lPQURERG2WTGgDt6DodDpoNBpUVVU1WA7+6tWrOHnyJHx8fGBjYyNRC6Xn7e2N6dOnY/r06VI3xSwff/wxpk+fjosXL1rsnMXFxfDx8cHevXsRGBjYaJnt27fjr3/9Ky5cuAAnJyeL1X078WediNqam31/36hFy8FT6w0fPtyiwWH37t2YNGmSxc73Z7Nnz4ZMJrvp1hJRUVE4evSohVtLRERtSZt4UB41Ta/XQ6lUws3N7bbWk5SUhMmTJ4uvBw0ahEmTJiE+Pv6m7boVW1tb3gVFJLEregM++vEEzl/WS90UktBzQ3zg5ayWpO52F0YEQcCVOoMkddtaK5o1QhAbG4sdO3Zgx44dWLx4MQDg5MmT8PLywqRJk/Ddd9+htLQU3bt3x5QpUzBt2jSTYy9evIhBgwYhMzMTKpUKJ0+ebHCZRiaTYcWKFfjmm2+wdetWeHp6YtGiRXj88ccBXF+f5VZ13cje3t5ksS2FQgEHBwfxlu7hw4fDz88PVlZW+PTTT+Hv74/vv/8e6enpWLVqFU6cOAFnZ2dERkbivffeE8/158s0s2fPxqZNm/Dqq69i1qxZuHDhAh5++GGsWLFCfAR1dnY23nnnHRw8eBAKhQKhoaFYvHgx7r33XpM2HzlyBFOmTMGePXvQs2dPZGZmYtiwYU3+vezcuRMzZ85EQUEBXF1dMWbMGKSmpsLOzu6Wf6dEbdnXB37Dom0coezoIgO6MoxYypU6A/olb5Wk7kNzI6BW3rpLFy9ejKNHj8LPzw9z584FcH0NCaPRiG7dumH9+vVwcXHBrl27MGnSJHTp0gXjxo0Tj9dqtXB0dMS2bdtuWs+cOXPw3nvvYeHChVi6dCnGjx+PU6dOwdnZudl1mWP16tV48cUXkZOTI+6Ty+VYsmQJfHx8cOLECUyZMgWvv/46/vGPfzR5nuPHj2PTpk34+uuvceHCBYwbNw5paWnipOeamhokJiaif//+qK6uRnJyMsaMGYN9+/aZTJ5+7bXXkJGRgX79+iE9PR2RkZE4efIkXFxcGq1z5MiReOedd5CVlYWKigokJCQgISEBq1atalF/ELUVv164AgDw99TggV6uEreGpOLuKN1ctHYXRtoCjUYDpVIJtVptslicQqEwWQbfx8cHubm5WLdunUlAsLOzw0cffXTLyyCxsbGIjo4GACxYsABLlixBfn4+Ro4cCWtr62bVZQ5fX1+89957JvtunBfj7e2Nd955B5MnT75pGDEajfj444/FkZBnn30WWq1WDCNPPPGESfmsrCy4ubnh0KFD8PPzE/cnJCSIZT/44ANkZ2dj5cqVeP311xvUmZqaivHjx4vt9fX1xZIlSzBs2DB88MEHnDBK7VpF9fVngf2tT2e88lAviVtDHVG7CyO21gocmhshWd2tlZmZiaysLJSUlODKlSvQ6/UN7gjx9/dv1nyM/v37i3+2s7ODo6MjysvLzarLHEFBQQ32ffvtt0hNTcWRI0eg0+lw7do1XL16FZcvX4Za3fhwoLe3txhEAKBLly4m7T527BiSk5ORl5eHyspKGI1GANdvK78xjNy4EJ+VlRWCg4Nx+PDhRuvcv38/Dhw4gM8++0zcJwgCjEYjTp48ib59+zazF4janopL18OIm0PzVr4msrR2F0ZkMlmzLpXcjdasWYOkpCQsWrQIoaGhcHBwwMKFC5GXl2dSrrlzGKytrU1ey2Qy8Yu7uXWZ48/tKi4uxmOPPYYXX3wR8+fPh7OzM3bu3ImJEydCr9c3GUZu1m7g+kJ6PXr0wIoVK9C1a1cYjUb4+flBr2/55Lvq6mq88MILePnllxu817179xafl6gtKP89jHRmGCGJtM1v7XZAqVTCYDCdaJuTk4OwsDBMmTJF3Hf8+PHbUv+dqKuwsBBGoxGLFi0S53KsW7euVec8d+4cioqKsGLFCgwdOhTA9Ymnjfnpp5/wwAMPAACuXbuGwsJCJCQkNFp24MCBOHToEHr27Nmq9hG1RZUcGSGJcZ0RiXh7eyMvLw/FxcXipQZfX18UFBRg69atOHr0KGbNmoXdu3fflvrvRF09e/ZEXV0dli5dihMnTuCTTz7B8uXLW3XOTp06wcXFBR9++CF++eUXfPfddyZPeL5RZmYmNm7ciCNHjmDq1Km4cOECnnvuuUbLvvHGG9i1axcSEhKwb98+HDt2DF999VWT4YWovRAEgZdpSHIMIxJJSkqCQqFAv3794ObmhpKSErzwwgsYO3YsoqKiEBISgnPnzpmMXFjSnagrICAA6enpePfdd+Hn54fPPvtMfGZRS8nlcqxZswaFhYXw8/PDK6+8goULFzZaNi0tDWlpaQgICMDOnTuxefNmuLo2fqdA//79sWPHDhw9ehRDhw7FgAEDkJycjK5du7aqvUR3u6orddAbrl8GZRghqXA5eKI2gj/rdDscK7uEh/7vB2hsrbE/ZYTUzaF2hsvBExHRLfESDd0NGEaIiDqw+jVG3OwZRkg6DCNERB1Yue7323odGUZIOgwjREQdGEdG6G7AMEJE1IFxzgjdDRhGiIg6sPJLVwHwMg1Ji2GEiKgDE0dG7Hm7OEmHYYSIqAPjZRq6GzCMkEV4e3sjIyPDoueMjY3F6NGjb1pm+PDhmD59ukXrJeoo9NeMuHC5DgAfkkfSYhiRyO34Em3Ol7dMJrvpNnv27BbVvXv3bkyaNKlFxxKRNCp/v5PGWiGDxtb6FqWJbh8+tbeDOXv2rPjntWvXIjk5GUVFReI+e3t78c+CIMBgMMDK6tY/Jm5ubpZtKBHddvWXaFztVZDLZRK3hjoyjoxIIDY2Fjt27MDixYvFEYni4mIAwMGDB/Hwww/D3t4e7u7uePbZZ1FZWSke+8UXX8Df3x+2trZwcXFBeHg4ampqMHv2bKxevRpfffWVeM7t27c3qNvDw0PcNBoNZDKZ+PrIkSNwcHDAf/7zHwQFBUGlUmHnzp04fvw4Ro0aBXd3d9jb22PQoEH49ttvTc7758s0MpkMH330EcaMGQO1Wg1fX19s3rxZfN9gMGDixInw8fGBra0tevfujcWLFzfaX3PmzIGbmxscHR0xefJk6PX6Jvu2trYWSUlJ8PT0hJ2dHUJCQhrtByLifBG6e7S/MCIIgL5Gmq2ZzxxcvHgxQkNDER8fj7Nnz+Ls2bPw8vLCxYsX8be//Q0DBgxAQUEBsrOzUVZWhnHjxgG4PqoRHR2N5557DocPH8b27dsxduxYCIKApKQkjBs3DiNHjhTPGRYW1qIunDFjBtLS0nD48GH0798f1dXVeOSRR6DVarF3716MHDkSkZGRKCkpuel55syZg3HjxuHAgQN45JFHMH78eJw/fx4AYDQa0a1bN6xfvx6HDh1CcnIy3nzzTaxbt87kHFqtVvys//73v7FhwwbMmTOnyToTEhKQm5uLNWvW4MCBA3jqqacwcuRIHDt2rEV9QdSelf8eRjhfhKTW/i7T1F0GFkj02Pc3fwOUdrcsptFooFQqoVar4eHhIe5ftmwZBgwYgAULFoj7srKy4OXlhaNHj6K6uhrXrl3D2LFj0aNHDwCAv7+/WNbW1ha1tbUm52yJuXPn4qGHHhJfOzs7IyAgQHw9b948bNy4EZs3b0ZCQkKT54mNjUV0dDQAYMGCBViyZAny8/MxcuRIWFtbm4QKHx8f5ObmYt26dWL4AgClUomsrCyo1Wrcd999mDt3Ll577TXMmzcPcrlpli4pKcGqVatQUlKCrl2v/wwkJSUhOzsbq1atMulXIuLICN092l8YacP279+P77//3mTeRr3jx49jxIgRePDBB+Hv74+IiAiMGDECTz75JDp16mTRdgQHB5u8rq6uxuzZs/HNN9/g7NmzuHbtGq5cuXLLkZH+/fuLf7azs4OjoyPKy8vFfZmZmcjKykJJSQmuXLkCvV6PwMBAk3MEBARArVaLr0NDQ1FdXY3Tp0+Lgazezz//DIPBgF69epnsr62thYuLS7M+O1FHUlF9fcEzLgVPUmt/YcRafX2EQqq6W6G6uhqRkZF49913G7zXpUsXKBQKbNu2Dbt27cJ///tfLF26FG+99Rby8vLg4+PTqrpvZGdnOrqTlJSEbdu24f3330fPnj1ha2uLJ5988qZzNwDA2tp0dr5MJoPRaAQArFmzBklJSVi0aBFCQ0Ph4OCAhQsXIi8vr8Xtrq6uhkKhQGFhIRQKhcl7jQU8oo6u/iF5bo5c8Iyk1f7CiEzWrEslUlMqlTAYDCb7Bg4ciC+//BLe3t5N3sEik8kwZMgQDBkyBMnJyejRowc2btyIxMTERs9pCTk5OYiNjcWYMWMAXP/Sr59w25pzhoWFYcqUKeK+48ePNyi3f/9+XLlyBba2tgCAn376Cfb29vDy8mpQdsCAATAYDCgvL8fQoUNb1T6ijoAPyaO7RfubwNpGeHt7Iy8vD8XFxaisrITRaMTUqVNx/vx5REdHY/fu3Th+/Di2bt2KuLg4GAwG5OXlYcGCBSgoKEBJSQk2bNiAiooK9O3bVzzngQMHUFRUhMrKStTV1Vmkrb6+vtiwYQP27duH/fv345lnnhFHOFpzzoKCAmzduhVHjx7FrFmzsHv37gbl9Ho9Jk6ciEOHDmHLli1ISUlBQkJCg/kiANCrVy+MHz8eMTEx2LBhA06ePIn8/Hykpqbim2++aVV7idojzhmhuwXDiESSkpKgUCjQr18/uLm5iZMuc3JyYDAYMGLECPj7+2P69OlwcnKCXC6Ho6MjfvjhBzzyyCPo1asX3n77bSxatAgPP/wwACA+Ph69e/dGcHAw3NzckJOTY5G2pqeno1OnTggLC0NkZCQiIiIwcODAVp3zhRdewNixYxEVFYWQkBCcO3fOZJSk3oMPPghfX1888MADiIqKwuOPP37ThdlWrVqFmJgYvPrqq+jduzdGjx6N3bt3o3v37q1qL1F7IwiCGEZ4Nw1JTSYIzbwfVUI6nQ4ajQZVVVVwdHQ0ee/q1as4efIkfHx8YGPD657UfvFnnSyp6kodAub8FwBwZN5I2FgrbnEEkflu9v19I46MEBF1QPWjIg42VgwiJLkWhZHMzEx4e3vDxsYGISEhyM/Pb7Ls8OHDG30GyqOPPtriRhMRUetwvgjdTcwOI2vXrkViYiJSUlKwZ88eBAQEICIiwmT9iBtt2LBBXBH07NmzOHjwIBQKBZ566qlWN56IiFqm/NL1NUY4X4TuBmaHkfT0dMTHxyMuLg79+vXD8uXLoVarkZWV1Wh5Z2dnk+ehbNu2DWq1mmGEiEhCf4yMcP4RSc+sMKLX61FYWIjw8PA/TiCXIzw8HLm5uc06x8qVK/H00083WFjrRrW1tdDpdCYbERFZDtcYobuJWWGksrISBoMB7u7uJvvd3d1RWlp6y+Pz8/Nx8OBBPP/88zctl5qaCo1GI26NLXBFREQtxzkjdDe5o3fTrFy5Ev7+/hg8ePBNy82cORNVVVXidvr06TvUQiKijoFrjNDdxKzl4F1dXaFQKFBWVmayv6ys7JZPiq2pqcGaNWswd+7cW9ajUqmgUvEfCBHR7cKREbqbmDUyolQqERQUBK1WK+4zGo3QarUIDQ296bHr169HbW0t/v73v7espUREZDEMI3Q3MfsyTWJiIlasWIHVq1fj8OHDePHFF1FTU4O4uDgAQExMDGbOnNnguJUrV2L06NF8lPtt4u3tjYyMDKmb0SbExsZi9OjRFj3nxx9/DCcnp5uWmT17NgIDAy1aL1FL1BmMOFdz/anbvExDdwOzw0hUVBTef/99JCcnIzAwEPv27UN2drY4qbWkpARnz541OaaoqAg7d+7ExIkTLdPqdmD48OGYPn26xc63e/duTJo0yWLna0xxcTFkMhk6d+6MS5cumbwXGBh402fG/FlzvrybWjCvfhs+fLj5HwLA4sWL8fHHH7foWKL24Fz19SCikMvQSa2UuDVEZs4ZqZeQkICEhIRG39u+fXuDfb1790YbeAROm6TX66FUKuHm5nbH6rx06RLef/99zJkz57bWs2HDBuj1139pnj59GoMHD8a3336L++67D8D1y4Y3qqurg7W19S3Pq9FoLN9Yojak/hKNq70ScrlM4tYQ8dk0koiNjcWOHTuwePFi8X/5xcXFMBgMmDhxInx8fGBra4vevXtj8eLFDY4dPXo05s+fj65du6J3794AGl6mkclk+OijjzBmzBio1Wr4+vpi8+bN4vvNqaspL730EtLT05tcdRcALly4gJiYGHTq1AlqtRoPP/wwjh07BuB6YI2Li0NVVZX4+RsbVblxwbz6sOXi4iLuc3FxwQcffIDHH38cdnZ2mD9/vll9WG/48OF4+eWX8frrr4t1/rk96enp8Pf3h52dHby8vDBlyhRUV1c3aPOmTZvg6+sLGxsbRERE3PJOsI8++gh9+/aFjY0N+vTpg3/84x83LU9kCRXV11df5XwRulu0aGTkbiYIAq5cuyJJ3bZWtpDJbv2/jMWLF+Po0aPw8/MT7y5yc3OD0WhEt27dsH79eri4uGDXrl2YNGkSunTpgnHjxonHa7VaODo6Ytu2bTetZ86cOXjvvfewcOFCLF26FOPHj8epU6fg7Ozc7LoaEx0djW3btmHu3LlYtmxZo2ViY2Nx7NgxbN68GY6OjnjjjTfwyCOP4NChQwgLC0NGRgaSk5NRVFQEALC3t79lvzVm9uzZSEtLQ0ZGBqysrFr8uVavXo3ExETk5eUhNzcXsbGxGDJkCB566CEA1xf3W7JkCXx8fHDixAlMmTIFr7/+ukl4uHz5MubPn49//etfUCqVmDJlCp5++mnk5OQ0Wudnn32G5ORkLFu2DAMGDMDevXsRHx8POzs7TJgwoUX9QdQc5br623q5+irdHdpdGLly7QpCPg+RpO68Z/KgtlbfspxGo4FSqYRarTa5JVqhUJhc+vDx8UFubi7WrVtn8kVqZ2eHjz76qMFlij+LjY1FdHQ0AGDBggVYsmQJ8vPzMXLkSFhbWzerrsbIZDKkpaUhMjISr7zyCu69916T9+tDSE5ODsLCwgBc/+L18vLCpk2b8NRTT0Gj0UAmk93ylvBbeeaZZ8TJ0/Va8rn69++PlJQUAICvry+WLVsGrVYrhpEb5/d4e3vjnXfeweTJk03CSF1dHZYtW4aQkOs/f6tXr0bfvn2Rn5/f6No6KSkpWLRoEcaOHSu29dChQ/jnP//JMEK3lXgnDVdfpbtEuwsjbV1mZiaysrJQUlKCK1euQK/XN7gDw9/f/5ZBBLj+BVvPzs4Ojo6OJpdWmlNXUyIiIvCXv/wFs2bNwueff27y3uHDh2FlZSV+KQPXL6/07t0bhw8fbtb5mys4OLjBvpZ8rhv7CgC6dOli0lfffvstUlNTceTIEeh0Oly7dg1Xr17F5cuXoVZfD6BWVlYYNGiQeEyfPn3g5OSEw4cPNwgjNTU1OH78OCZOnIj4+Hhx/7Vr1zinhW47cSl4Xqahu0S7CyO2VrbIeyZPsrpbY82aNUhKSsKiRYsQGhoKBwcHLFy4EHl5pp/nZs/1udGfJ3PKZDIYjUaz6rqZtLQ0hIaG4rXXXmv2MZb2575o6ee6WV8VFxfjsccew4svvoj58+fD2dlZvDtMr9eLYcQc9fNNVqxYYRLagOsjZES3k3iZxpFhhO4O7S6MyGSyZl0qkZpSqYTBYDDZV39ZY8qUKeK+48eP35b6LVHX4MGDMXbsWMyYMcNkf9++fXHt2jXk5eWJl2nOnTuHoqIi9OvXD0Djn98SbkcfFhYWwmg0YtGiRZDLr8/5XrduXYNy165dQ0FBgTgKUlRUhIsXL6Jv374Nyrq7u6Nr1644ceIExo8f36r2EZmLD8mju027CyNthbe3N/Ly8lBcXAx7e3s4OzvD19cX//rXv7B161b4+Pjgk08+we7du+Hj42Px+i1V1/z583HffffByuqPHyVfX1+MGjUK8fHx+Oc//wkHBwfMmDEDnp6eGDVqFIDrn7+6uhparRYBAQFQq9UtGmG4XZ/rRj179kRdXR2WLl2KyMhI5OTkYPny5Q3KWVtb46WXXsKSJUtgZWWFhIQE3H///U0+i2nOnDl4+eWXodFoMHLkSNTW1qKgoAAXLlxAYmJii9tL0vrxWAW+O9L0nWZ3g1/Kr4/M8TIN3S0YRiSSlJSECRMmoF+/frhy5QpOnjyJF154AXv37kVUVBRkMhmio6MxZcoU/Oc//7F4/Zaqq1evXnjuuefw4YcfmuxftWoVpk2bhsceewx6vR4PPPAAtmzZIl4OCQsLw+TJkxEVFYVz584hJSXFrEXTbvfnulFAQADS09Px7rvvYubMmXjggQeQmpqKmJgYk3JqtRpvvPEGnnnmGZw5cwZDhw7FypUrmzzv888/D7VajYULF+K1116DnZ0d/P39LboYHt15L/97Ly5crpO6Gc3i2al1l5aJLEUmtIHVyHQ6HTQaDaqqquDo6Gjy3tWrV3Hy5En4+PjAxoa3qVH7xZ/1u19N7TXcl7IVADB52L1Q3MUrOfXt4ojH+neVuhnUzt3s+/tGHBkhIrKQ+ltm1UoFZjzcR+LWELUdd3FuJyJqW3jLLFHLMIwQEVnIHyubMowQmYNhhIjIQiou8ZkvRC3BMEJEZCFcv4OoZRhGiIgs5I+VTXm3E5E5GEaIiCyEIyNELcMwQkRkIeLTcDlnhMgsDCNERBbCMELUMgwj1CYVFxdDJpNh3759Fj2vt7c3MjIyblpGJpNh06ZNFq2X2j6DUUBlNW/tJWoJhhGJDB8+3OLPIImNjcXo0aObVU4mkyEtLc1k/6ZNmyCTycyq81Zf3tu3b4dMJrvptn37drPqBAAvLy+cPXsWfn5+Zh9LdDucr9HDKAAyGeBsp5S6OURtCsNIB2VjY4N3330XFy5cuK31hIWF4ezZs+I2btw4jBw50mRfWFiYWF6v1zfrvAqFAh4eHiZPCyaSUv0lGhc7Jazu5ofSEN2F+C9GArGxsdixYwcWL14sjg4UFxcDAA4ePIiHH34Y9vb2cHd3x7PPPovKykrx2C+++AL+/v6wtbWFi4sLwsPDUVNTg9mzZ2P16tX46quvmjXiEB4eDg8PD6Smpt60rV9++SXuu+8+qFQqeHt7Y9GiReJ7w4cPx6lTp/DKK6+Idf6ZUqmEh4eHuNna2kKlUomvly9fjsGDB+Ojjz4yeQBcdnY2/vKXv8DJyQkuLi547LHHcPz4cfG8f75MUz8Co9VqERwcDLVajbCwMBQVFYnHHD9+HKNGjYK7uzvs7e0xaNAgfPvttw3afOnSJURHR8POzg6enp7IzMy8aR+dPn0a48aNg5OTE5ydnTFq1Cjx75M6jnJxwTPe1ktkrnYXRgRBgPHyZUm25j4AefHixQgNDUV8fLw4OuDl5YWLFy/ib3/7GwYMGICCggJkZ2ejrKwM48aNAwCcPXsW0dHReO6553D48GFs374dY8eOhSAISEpKajDqcOOIw58pFAosWLAAS5cuxa+//tpomcLCQowbNw5PP/00fv75Z8yePRuzZs3Cxx9/DADYsGEDunXrhrlz54p1tsQvv/yCL7/8Ehs2bBDDRU1NDRITE1FQUACtVgu5XI4xY8bAaDTe9FxvvfUWFi1ahIKCAlhZWeG5554T36uursYjjzwCrVaLvXv3YuTIkYiMjERJSYnJORYuXIiAgADs3bsXM2bMwLRp07Bt27ZG66urq0NERAQcHBzw448/IicnB/b29hg5cmSzR3mofeDkVaKWa3dj3MKVKygaGCRJ3b33FEKmVt+ynEajgVKphFqthoeHh7h/2bJlGDBgABYsWCDuy8rKgpeXF44ePYrq6mpcu3YNY8eORY8ePQAA/v7+YllbW1vU1taanPNmxowZg8DAQKSkpGDlypUN3k9PT8eDDz6IWbNmAQB69eqFQ4cOYeHChYiNjYWzszMUCgUcHByaXWdj9Ho9/vWvf8HNzU3c98QTT5iUycrKgpubGw4dOnTTeSLz58/HsGHDAAAzZszAo48+iqtXr8LGxgYBAQEICAgQy86bNw8bN27E5s2bkZCQIO4fMmQIZsyYIX7mnJwc/N///R8eeuihBvWtXbsWRqMRH330kTgytGrVKjg5OWH79u0YMWJEC3qE2iKuMULUcu1uZKQt279/P77//nvY29uLW58+1x9Dfvz4cQQEBODBBx+Ev78/nnrqKaxYsaLVcz7effddrF69GocPH27w3uHDhzFkyBCTfUOGDMGxY8dgMBhaVe+NevToYRJEAODYsWOIjo7GPffcA0dHR3h7ewNAg1GMP+vfv7/45y5dugAAysvLAVwfGUlKSkLfvn3h5OQEe3t7HD58uME5Q0NDG7xurH+A639nv/zyCxwcHMS/M2dnZ1y9etXkshK1f/UjI50dGUaIzNXuRkZktrbovadQsrpbo7q6GpGRkXj33XcbvNelSxcoFAps27YNu3btwn//+18sXboUb731FvLy8uDj49OiOh944AFERERg5syZiI2NbVX7W8rOzq7BvsjISPTo0QMrVqxA165dYTQa4efnd8tLH9bW1uKf60cq6i/tJCUlYdu2bXj//ffRs2dP2Nra4sknn2zV5ZTq6moEBQXhs88+a/DenwMWtW/llzgyQtRS7S+MyGTNulQiNaVS2WB0YeDAgfjyyy/h7e3d5F0iMpkMQ4YMwZAhQ5CcnIwePXpg48aNSExMbPSczZGWlobAwED07t3bZH/fvn2Rk5Njsi8nJwe9evWCQqFo8nO01rlz51BUVIQVK1Zg6NChAICdO3e2+rw5OTmIjY3FmDFjAFwPEo1NNP3pp58avO7bt2+j5xw4cCDWrl2Lzp07w9HRsdVtpLaLc0aIWo6XaSTi7e2NvLw8FBcXo7KyEkajEVOnTsX58+cRHR2N3bt34/jx49i6dSvi4uJgMBiQl5eHBQsWoKCgACUlJdiwYQMqKirEL0pvb28cOHAARUVFqKysRF1dXbPa4u/vj/Hjx2PJkiUm+1999VVotVrMmzcPR48exerVq7Fs2TIkJSWZfI4ffvgBZ86cMbnrpzU6deoEFxcXfPjhh/jll1/w3XffITExsdXn9fX1FSfJ7t+/H88880yjE2JzcnLw3nvv4ejRo8jMzMT69esxbdq0Rs85fvx4uLq6YtSoUfjxxx9x8uRJbN++HS+//HKTE4OpfapkGCFqMYYRiSQlJUGhUKBfv35wc3NDSUkJunbtipycHBgMBowYMQL+/v6YPn06nJycIJfL4ejoiB9++AGPPPIIevXqhbfffhuLFi3Cww8/DACIj49H7969ERwcDDc3twajGjczd+7cBl/MAwcOxLp167BmzRr4+fkhOTkZc+fONbmcM3fuXBQXF+Pee++12GUJuVyONWvWoLCwEH5+fnjllVewcOHCVp83PT0dnTp1QlhYGCIjIxEREYGBAwc2KPfqq6+ioKAAAwYMwDvvvIP09HREREQ0ek61Wo0ffvgB3bt3x9ixY9G3b19MnDgRV69e5UhJB1N/mYarrxKZTyY0935UCel0Omg0GlRVVTX4BX/16lWcPHnSZI0KovaIP+t3r8v6a+iXvBUA8PPsEXCwsb7FEUQdw82+v2/EkREiolaqvHR9ErSNtRz2qnY3FY/otmMYISJqpfrVVzs72Jj9fCciamEYyczMhLe3N2xsbBASEoL8/Pyblr948SKmTp2KLl26QKVSoVevXtiyZUuLGkxEdLfhnTRErWP2eOLatWuRmJiI5cuXIyQkBBkZGYiIiEBRURE6d+7coLxer8dDDz2Ezp0744svvoCnpydOnToFJycnS7SfiEhyXH2VqHXMDiPp6emIj49HXFwcAGD58uX45ptvkJWVJS6hfaOsrCycP38eu3btEhekql9Nk4ioPeDICFHrmHWZRq/Xo7CwEOHh4X+cQC5HeHg4cnNzGz1m8+bNCA0NxdSpU+Hu7g4/Pz8sWLDgpgtl1dbWQqfTmWy30gZuCiJqFf6M373Kdbytl6g1zAojlZWVMBgMcHd3N9nv7u6O0tLSRo85ceIEvvjiCxgMBmzZsgWzZs3CokWL8M477zRZT2pqKjQajbh5eXk1WbZ+JVA+IZXau/qf8fqfebp7iJdpGEaIWuS234NmNBrRuXNnfPjhh1AoFAgKCsKZM2ewcOFCpKSkNHrMzJkzTVbc1Ol0TQYSKysrqNVqVFRUwNraGnI5bxCi9sdoNKKiogJqtbrJRwWQdHiZhqh1zPqt5urqCoVCgbKyMpP9ZWVlTT5CvkuXLrC2tjb531zfvn1RWloKvV4PpVLZ4BiVSgWVqnn/qGUyGbp06YKTJ0/i1KlTZnwaorZFLpeje/fuvHX0LnTjrb1EZD6zwohSqURQUBC0Wi1Gjx4N4Pr/2LRaLRISEho9ZsiQIfj8889hNBrFUYujR4+iS5cujQaRllAqlfD19eWlGmrXlEolR/7uQkajgMrq6797ODJC1DJmj/cmJiZiwoQJCA4OxuDBg5GRkYGamhrx7pqYmBh4enoiNTUVAPDiiy9i2bJlmDZtGl566SUcO3YMCxYswMsvv2zRDyKXy7lENhHdcRcu62EwXp9c7GJvmf9gEXU0ZoeRqKgoVFRUIDk5GaWlpQgMDER2drY4qbWkpMTkf29eXl7YunUrXnnlFfTv3x+enp6YNm0a3njjDct9CiIiidRPXnW2U8JawZEropZo8w/KIyKS0g9HKxCTlY8+Hg7Inv6A1M0huqvwQXlERHcA76Qhaj2GESKiVuBS8EStxzBCRNQK9auvujkyjBC1FMMIEVErcGSEqPUYRoiIWqHi9wXPOGeEqOUYRoiIWqF+AitXXyVqOYYRIqJWKOfdNEStxjBCRNRCV+sMuHT1GgCGEaLWYBghImqh+ks0Sis5HG34NGWilmIYISJqoXJxvoiKT1MmagWGESKiFuLqq0SW0aHHFVfuPIlfL1wWXwuCgOO1W1FtKJOwVUTUVly8XAeV+xVU26nxbv5OqZtD1Cp/7/d3eNp7SlJ3hw4j3xz4DXtKLoqv5Ta/ws7nY8naQ0RtjAJQOgOlAD49LHVjiFpnpM9IhhEpPBHUDaH3uoivT12twI6LgJ3cFffYDpWuYUTUZljJ5ejX1RFqZYf+dUrtQGfbzpLV3aH/9YwP6WHy+t9H9mJHHhDaLRD/99e5ErWKiIioY+EE1htUXqkEALjYutyiJBEREVkKw8gN6sOIm62bxC0hIiLqOBhGblAfRlxtXSVuCRERUcfBMHIDhhEiIqI7j2HkBpWXfw8jaoYRIiKiO4Vh5HdGwYhzV88BAFxtGEaIiIjuFIaR312svQiDYAAAONs6S9waIiKijoNh5Hf180U6qTrBWm4tcWuIiIg6DoaR33G+CBERkTQYRn5XefX3MML5IkRERHcUw8jveFsvERGRNBhGfldxuQIAL9MQERHdaQwjvzt3hbf1EhERSYFh5HfinBFepiEiIrqjGEZ+xzkjRERE0mAY+R1v7SUiIpIGwwiAq9eu4lLdJQAcGSEiIrrTWhRGMjMz4e3tDRsbG4SEhCA/P7/Jsh9//DFkMpnJZmNj0+IG3w71z6RRypVwsHaQuDVEREQdi9lhZO3atUhMTERKSgr27NmDgIAAREREoLy8vMljHB0dcfbsWXE7depUqxptafW39bqp3SCTySRuDRERUcdidhhJT09HfHw84uLi0K9fPyxfvhxqtRpZWVlNHiOTyeDh4SFu7u7urWq0pdXf1uti6yJxS4iIiDoes8KIXq9HYWEhwsPD/ziBXI7w8HDk5uY2eVx1dTV69OgBLy8vjBo1Cv/73/9uWk9tbS10Op3JdjuJd9JwjREiIqI7zqwwUllZCYPB0GBkw93dHaWlpY0e07t3b2RlZeGrr77Cp59+CqPRiLCwMPz6669N1pOamgqNRiNuXl5e5jTTbFxjhIiISDq3/W6a0NBQxMTEIDAwEMOGDcOGDRvg5uaGf/7zn00eM3PmTFRVVYnb6dOnb2sbuRQ8ERGRdKzMKezq6gqFQoGysjKT/WVlZfDw8GjWOaytrTFgwAD88ssvTZZRqVRQqVTmNK1VxKXgOTJCRER0x5k1MqJUKhEUFAStVivuMxqN0Gq1CA0NbdY5DAYDfv75Z3Tp0sW8lt5GnDNCREQkHbNGRgAgMTEREyZMQHBwMAYPHoyMjAzU1NQgLi4OABATEwNPT0+kpqYCAObOnYv7778fPXv2xMWLF7Fw4UKcOnUKzz//vGU/SStUXPnj1l4iIiK6s8wOI1FRUaioqEBycjJKS0sRGBiI7OxscVJrSUkJ5PI/BlwuXLiA+Ph4lJaWolOnTggKCsKuXbvQr18/y32KVjAKRnHRM16mISIiuvNkgiAIUjfiVnQ6HTQaDaqqquDo6GjRc1+8ehFD1w4FABT+vRBKhdKi5yciIuqomvv93eGfTVM/X0Sj0jCIEBERSaDDhxFxvogt54sQERFJocOHkfqRES4FT0REJI0OH0a4xggREZG0OnwY4WUaIiIiaXX4MCIueMaRESIiIkl0+DBSf5mGc0aIiIik0eHDCEdGiIiIpNXhwwjnjBAREUmrQ4cRvUEPnV4HgCMjREREUunQYaR+voi13BqOSssuM09ERETN06HDSP0lGldbV8hkMolbQ0RE1DF16DDCyatERETSYxgBb+slIiKSUocOI1wKnoiISHodOozwtl4iIiLpdegwwjkjRERE0uvQYYRLwRMREUnPSuoGSGms71gM6DwAPZ16St0UIiKiDqtDh5Enej0hdROIiIg6vA59mYaIiIikxzBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFItCiOZmZnw9vaGjY0NQkJCkJ+f36zj1qxZA5lMhtGjR7ekWiIiImqHzA4ja9euRWJiIlJSUrBnzx4EBAQgIiIC5eXlNz2uuLgYSUlJGDp0aIsbS0RERO2P2WEkPT0d8fHxiIuLQ79+/bB8+XKo1WpkZWU1eYzBYMD48eMxZ84c3HPPPa1qMBEREbUvZoURvV6PwsJChIeH/3ECuRzh4eHIzc1t8ri5c+eic+fOmDhxYrPqqa2thU6nM9mIiIiofTIrjFRWVsJgMMDd3d1kv7u7O0pLSxs9ZufOnVi5ciVWrFjR7HpSU1Oh0WjEzcvLy5xmEhERURtyW++muXTpEp599lmsWLECrq6uzT5u5syZqKqqErfTp0/fxlYSERGRlKzMKezq6gqFQoGysjKT/WVlZfDw8GhQ/vjx4yguLkZkZKS4z2g0Xq/YygpFRUW49957GxynUqmgUqnMaRoRERG1UWaNjCiVSgQFBUGr1Yr7jEYjtFotQkNDG5Tv06cPfv75Z+zbt0/cHn/8cfz1r3/Fvn37ePmFiIiIzBsZAYDExERMmDABwcHBGDx4MDIyMlBTU4O4uDgAQExMDDw9PZGamgobGxv4+fmZHO/k5AQADfYTERFRx2R2GImKikJFRQWSk5NRWlqKwMBAZGdni5NaS0pKIJdzYVciIiJqHpkgCILUjbgVnU4HjUaDqqoqODo6St0cIiIiaobmfn9zCIOIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJqkVhJDMzE97e3rCxsUFISAjy8/ObLLthwwYEBwfDyckJdnZ2CAwMxCeffNLiBhMREVH7YnYYWbt2LRITE5GSkoI9e/YgICAAERERKC8vb7S8s7Mz3nrrLeTm5uLAgQOIi4tDXFwctm7d2urGExERUdsnEwRBMOeAkJAQDBo0CMuWLQMAGI1GeHl54aWXXsKMGTOadY6BAwfi0Ucfxbx585pVXqfTQaPRoKqqCo6OjuY0l4iIiCTS3O9vs0ZG9Ho9CgsLER4e/scJ5HKEh4cjNzf3lscLggCtVouioiI88MADTZarra2FTqcz2YiIiKh9MiuMVFZWwmAwwN3d3WS/u7s7SktLmzyuqqoK9vb2UCqVePTRR7F06VI89NBDTZZPTU2FRqMRNy8vL3OaSURERG3IHbmbxsHBAfv27cPu3bsxf/58JCYmYvv27U2WnzlzJqqqqsTt9OnTd6KZREREJAErcwq7urpCoVCgrKzMZH9ZWRk8PDyaPE4ul6Nnz54AgMDAQBw+fBipqakYPnx4o+VVKhVUKpU5TSMiIqI2yqyREaVSiaCgIGi1WnGf0WiEVqtFaGhos89jNBpRW1trTtVERETUTpk1MgIAiYmJmDBhAoKDgzF48GBkZGSgpqYGcXFxAICYmBh4enoiNTUVwPX5H8HBwbj33ntRW1uLLVu24JNPPsEHH3xg2U9CREREbZLZYSQqKgoVFRVITk5GaWkpAgMDkZ2dLU5qLSkpgVz+x4BLTU0NpkyZgl9//RW2trbo06cPPv30U0RFRVnuUxAREVGbZfY6I1LgOiNERERtz21ZZ4SIiIjI0hhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSbUojGRmZsLb2xs2NjYICQlBfn5+k2VXrFiBoUOHolOnTujUqRPCw8NvWp6IiIg6FrPDyNq1a5GYmIiUlBTs2bMHAQEBiIiIQHl5eaPlt2/fjujoaHz//ffIzc2Fl5cXRowYgTNnzrS68URERNT2yQRBEMw5ICQkBIMGDcKyZcsAAEajEV5eXnjppZcwY8aMWx5vMBjQqVMnLFu2DDExMc2qU6fTQaPRoKqqCo6OjuY0l4iIiCTS3O9vs0ZG9Ho9CgsLER4e/scJ5HKEh4cjNze3Wee4fPky6urq4Ozs3GSZ2tpa6HQ6k42IiIjaJ7PCSGVlJQwGA9zd3U32u7u7o7S0tFnneOONN9C1a1eTQPNnqamp0Gg04ubl5WVOM4mIiKgNuaN306SlpWHNmjXYuHEjbGxsmiw3c+ZMVFVVidvp06fvYCuJiIjoTrIyp7CrqysUCgXKyspM9peVlcHDw+Omx77//vtIS0vDt99+i/79+9+0rEqlgkqlMqdpRERE1EaZNTKiVCoRFBQErVYr7jMajdBqtQgNDW3yuPfeew/z5s1DdnY2goODW95aIiIianfMGhkBgMTEREyYMAHBwcEYPHgwMjIyUFNTg7i4OABATEwMPD09kZqaCgB49913kZycjM8//xze3t7i3BJ7e3vY29tb8KMQERFRW2R2GImKikJFRQWSk5NRWlqKwMBAZGdni5NaS0pKIJf/MeDywQcfQK/X48knnzQ5T0pKCmbPnt261hMREVGbZ/Y6I1LgOiNERERtz21ZZ4SIiIjI0hhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSbUojGRmZsLb2xs2NjYICQlBfn5+k2X/97//4YknnoC3tzdkMhkyMjJa2lYiIiJqh8wOI2vXrkViYiJSUlKwZ88eBAQEICIiAuXl5Y2Wv3z5Mu655x6kpaXBw8Oj1Q0mIiKi9sXsMJKeno74+HjExcWhX79+WL58OdRqNbKyshotP2jQICxcuBBPP/00VCpVqxtMRERE7YtZYUSv16OwsBDh4eF/nEAuR3h4OHJzcy3WqNraWuh0OpONiIiI2iezwkhlZSUMBgPc3d1N9ru7u6O0tNRijUpNTYVGoxE3Ly8vi52biIiI7i535d00M2fORFVVlbidPn1a6iYRERHRbWJlTmFXV1coFAqUlZWZ7C8rK7Po5FSVSsX5JURERB2EWSMjSqUSQUFB0Gq14j6j0QitVovQ0FCLN46IiIjaP7NGRgAgMTEREyZMQHBwMAYPHoyMjAzU1NQgLi4OABATEwNPT0+kpqYCuD7p9dChQ+Kfz5w5g3379sHe3h49e/a04EchIiKitsjsMBIVFYWKigokJyejtLQUgYGByM7OFie1lpSUQC7/Y8Dlt99+w4ABA8TX77//Pt5//30MGzYM27dvb/0nICIiojZNJgiCIHUjbkWn00Gj0aCqqgqOjo5SN4eIiIiaobnf33fl3TRERETUcTCMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmpRGMnMzIS3tzdsbGwQEhKC/Pz8m5Zfv349+vTpAxsbG/j7+2PLli0taiwRERG1P2aHkbVr1yIxMREpKSnYs2cPAgICEBERgfLy8kbL79q1C9HR0Zg4cSL27t2L0aNHY/To0Th48GCrG09ERERtn0wQBMGcA0JCQjBo0CAsW7YMAGA0GuHl5YWXXnoJM2bMaFA+KioKNTU1+Prrr8V9999/PwIDA7F8+fJm1anT6aDRaFBVVQVHR0dzmtskwWiEoDtvkXMRERG1dTJHZ8jklp290dzvbytzTqrX61FYWIiZM2eK++RyOcLDw5Gbm9voMbm5uUhMTDTZFxERgU2bNjVZT21tLWpra8XXOp3OnGY2i6A7j6L7h1r8vERERG1R759+hMzJVZK6zYpAlZWVMBgMcHd3N9nv7u6O0tLSRo8pLS01qzwApKamQqPRiJuXl5c5zSQiIqI2xKyRkTtl5syZJqMpOp3O4oFE5uiM3j/9aNFzEhERtVUyR2fJ6jYrjLi6ukKhUKCsrMxkf1lZGTw8PBo9xsPDw6zyAKBSqaBSqcxpmtlkcrlkw1FERET0B7Mu0yiVSgQFBUGr1Yr7jEYjtFotQkNDGz0mNDTUpDwAbNu2rcnyRERE1LGYfZkmMTEREyZMQHBwMAYPHoyMjAzU1NQgLi4OABATEwNPT0+kpqYCAKZNm4Zhw4Zh0aJFePTRR7FmzRoUFBTgww8/tOwnISIiojbJ7DASFRWFiooKJCcno7S0FIGBgcjOzhYnqZaUlEB+w61BYWFh+Pzzz/H222/jzTffhK+vLzZt2gQ/Pz/LfQoiIiJqs8xeZ0QKt2OdESIiIrq9mvv9zWfTEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkzF4OXgr1i8TqdDqJW0JERETNVf+9favF3ttEGLl06RIAwMvLS+KWEBERkbkuXboEjUbT5Ptt4tk0RqMRv/32GxwcHCCTySx2Xp1OBy8vL5w+fZrPvLnN2Nd3Dvv6zmJ/3zns6zvHUn0tCAIuXbqErl27mjxE98/axMiIXC5Ht27dbtv5HR0d+YN9h7Cv7xz29Z3F/r5z2Nd3jiX6+mYjIvU4gZWIiIgkxTBCREREkurQYUSlUiElJQUqlUrqprR77Os7h319Z7G/7xz29Z1zp/u6TUxgJSIiovarQ4+MEBERkfQYRoiIiEhSDCNEREQkKYYRIiIiklSHDiOZmZnw9vaGjY0NQkJCkJ+fL3WT2rzU1FQMGjQIDg4O6Ny5M0aPHo2ioiKTMlevXsXUqVPh4uICe3t7PPHEEygrK5Ooxe1DWloaZDIZpk+fLu5jP1vWmTNn8Pe//x0uLi6wtbWFv78/CgoKxPcFQUBycjK6dOkCW1tbhIeH49ixYxK2uG0yGAyYNWsWfHx8YGtri3vvvRfz5s0zebYJ+7plfvjhB0RGRqJr166QyWTYtGmTyfvN6dfz589j/PjxcHR0hJOTEyZOnIjq6urWN07ooNasWSMolUohKytL+N///ifEx8cLTk5OQllZmdRNa9MiIiKEVatWCQcPHhT27dsnPPLII0L37t2F6upqsczkyZMFLy8vQavVCgUFBcL9998vhIWFSdjqti0/P1/w9vYW+vfvL0ybNk3cz362nPPnzws9evQQYmNjhby8POHEiRPC1q1bhV9++UUsk5aWJmg0GmHTpk3C/v37hccff1zw8fERrly5ImHL25758+cLLi4uwtdffy2cPHlSWL9+vWBvby8sXrxYLMO+bpktW7YIb731lrBhwwYBgLBx40aT95vTryNHjhQCAgKEn376Sfjxxx+Fnj17CtHR0a1uW4cNI4MHDxamTp0qvjYYDELXrl2F1NRUCVvV/pSXlwsAhB07dgiCIAgXL14UrK2thfXr14tlDh8+LAAQcnNzpWpmm3Xp0iXB19dX2LZtmzBs2DAxjLCfLeuNN94Q/vKXvzT5vtFoFDw8PISFCxeK+y5evCioVCrh3//+951oYrvx6KOPCs8995zJvrFjxwrjx48XBIF9bSl/DiPN6ddDhw4JAITdu3eLZf7zn/8IMplMOHPmTKva0yEv0+j1ehQWFiI8PFzcJ5fLER4ejtzcXAlb1v5UVVUBAJydnQEAhYWFqKurM+n7Pn36oHv37uz7Fpg6dSoeffRRk/4E2M+WtnnzZgQHB+Opp55C586dMWDAAKxYsUJ8/+TJkygtLTXpb41Gg5CQEPa3mcLCwqDVanH06FEAwP79+7Fz5048/PDDANjXt0tz+jU3NxdOTk4IDg4Wy4SHh0MulyMvL69V9beJB+VZWmVlJQwGA9zd3U32u7u748iRIxK1qv0xGo2YPn06hgwZAj8/PwBAaWkplEolnJycTMq6u7ujtLRUgla2XWvWrMGePXuwe/fuBu+xny3rxIkT+OCDD5CYmIg333wTu3fvxssvvwylUokJEyaIfdrY7xT2t3lmzJgBnU6HPn36QKFQwGAwYP78+Rg/fjwAsK9vk+b0a2lpKTp37mzyvpWVFZydnVvd9x0yjNCdMXXqVBw8eBA7d+6UuintzunTpzFt2jRs27YNNjY2Ujen3TMajQgODsaCBQsAAAMGDMDBgwexfPlyTJgwQeLWtS/r1q3DZ599hs8//xz33Xcf9u3bh+nTp6Nr167s63asQ16mcXV1hUKhaHBnQVlZGTw8PCRqVfuSkJCAr7/+Gt9//z26desm7vfw8IBer8fFixdNyrPvzVNYWIjy8nIMHDgQVlZWsLKywo4dO7BkyRJYWVnB3d2d/WxBXbp0Qb9+/Uz29e3bFyUlJQAg9il/p7Tea6+9hhkzZuDpp5+Gv78/nn32WbzyyitITU0FwL6+XZrTrx4eHigvLzd5/9q1azh//nyr+75DhhGlUomgoCBotVpxn9FohFarRWhoqIQta/sEQUBCQgI2btyI7777Dj4+PibvBwUFwdra2qTvi4qKUFJSwr43w4MPPoiff/4Z+/btE7fg4GCMHz9e/DP72XKGDBnS4Bb1o0ePokePHgAAHx8feHh4mPS3TqdDXl4e+9tMly9fhlxu+tWkUChgNBoBsK9vl+b0a2hoKC5evIjCwkKxzHfffQej0YiQkJDWNaBV01/bsDVr1ggqlUr4+OOPhUOHDgmTJk0SnJychNLSUqmb1qa9+OKLgkajEbZv3y6cPXtW3C5fviyWmTx5stC9e3fhu+++EwoKCoTQ0FAhNDRUwla3DzfeTSMI7GdLys/PF6ysrIT58+cLx44dEz777DNBrVYLn376qVgmLS1NcHJyEr766ivhwIEDwqhRo3i7aQtMmDBB8PT0FG/t3bBhg+Dq6iq8/vrrYhn2dctcunRJ2Lt3r7B3714BgJCeni7s3btXOHXqlCAIzevXkSNHCgMGDBDy8vKEnTt3Cr6+vry1t7WWLl0qdO/eXVAqlcLgwYOFn376SeomtXkAGt1WrVollrly5YowZcoUoVOnToJarRbGjBkjnD17VrpGtxN/DiPsZ8v6f//v/wl+fn6CSqUS+vTpI3z44Ycm7xuNRmHWrFmCu7u7oFKphAcffFAoKiqSqLVtl06nE6ZNmyZ0795dsLGxEe655x7hrbfeEmpra8Uy7OuW+f777xv9/TxhwgRBEJrXr+fOnROio6MFe3t7wdHRUYiLixMuXbrU6rbJBOGGZe2IiIiI7rAOOWeEiIiI7h4MI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUnq/wOuqgPLWuAutAAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Trainable\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Trainable\")\n",
    "\n",
    "plt.plot(history_2.history['accuracy'], label = \"tarina Not Trainable\")\n",
    "plt.plot(history_2.history['val_accuracy'], label = \"test Not Trainable\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
