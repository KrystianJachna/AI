{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "\n",
    "Napisz (od podstaw) algorytm znajdowania minimum metodą gradientową.\n",
    "Zaprezentuj jego działanie na przykładzie funkcji $f(x)=x^2$, startując z punktu $x=2$. Zilustruj całą sytuacje oznaczając na wykresie 5 pierwszych iteracji."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:31.181270Z",
     "start_time": "2024-05-19T18:38:31.027144Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = lambda x: x**2\n",
    "\n",
    "x = np.linspace(-5, 5, 200)\n",
    "y = f(x)\n",
    "plt.plot(x, y, '--k', ms=10);\n",
    "\n",
    "\n",
    "def step_gradient_1d(x_current, learningRate):\n",
    "    x_gradient = 2*x_current\n",
    "    new_x = x_current - learningRate*x_gradient\n",
    "    \n",
    "    plt.arrow(x_current, f(x_current), - (learningRate * x_gradient), -(f(x_current)-f(new_x)),\n",
    "              head_width=0.05, head_length=0.5,ec=\"red\")\n",
    "        \n",
    "    return new_x\n",
    "def gradient_descent_runner_1d(starting_x, learning_rate, num_iterations):\n",
    "    x = starting_x\n",
    "    print(x)\n",
    "    for i in range(num_iterations):\n",
    "        x = step_gradient_1d(x,learning_rate)\n",
    "        #print(x)\n",
    "    return x\n",
    "\n",
    "learning_rate = 0.2\n",
    "initial_x = 5 \n",
    "num_iterations = 30\n",
    "x = gradient_descent_runner_1d(initial_x, learning_rate, num_iterations)\n",
    "\n",
    "plt.show()\n"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "Wykonaj powyższe zadania dla \n",
    "  * learning_rate = 0.001\n",
    "  * learning_rate = 0.1\n",
    "  * learning_rate = 0.2\n",
    "  * learning_rate = 0.5\n",
    "  * learning_rate = 0.9\n",
    "  * learning_rate = 0.99\n",
    "  * learning_rate = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:33.058448Z",
     "start_time": "2024-05-19T18:38:31.186843Z"
    }
   },
   "source": [
    "learning_rates = [0.001, 0.1, 0.2, 0.5, 0.9, 0.99, 0.999]\n",
    "\n",
    "x = np.linspace(-5, 5, 200)\n",
    "y = f(x)\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    plt.figure()\n",
    "    plt.plot(x, y, '--k', ms=10)\n",
    "    x_min = gradient_descent_runner_1d(initial_x, learning_rate, num_iterations)\n",
    "    plt.title(f'Learning rate: {learning_rate}, Minimum at x = {x_min}')\n",
    "    plt.show()"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2\n",
    "\n",
    "Napisz (od podstaw) algorytm znajdowania minimum metodą gradientową.\n",
    "Zaprezentuj jego działanie na przykładzie funkcji \n",
    "\n",
    "$$\n",
    "f(x,y)=4*x^2-2x+y^2,\n",
    "$$ \n",
    "\n",
    "startując z punktu $(x,y)=(2,2)$. Zilustruj całą sytuacje oznaczając na wykresie kilka pierwszych iteracji.\n",
    "Wykonaj obrazek 3D."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:33.521647Z",
     "start_time": "2024-05-19T18:38:33.060060Z"
    }
   },
   "source": [
    "###########\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "#%matplotlib notebook\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fun = lambda x,y: 4*x**2+y**2\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-7, 7, 0.25)\n",
    "Y = np.arange(-7, 7, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = fun(X, Y)\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0.01, antialiased=True, alpha=0.3)\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "def step_gradient_2d(x_current, y_current, learningRate):\n",
    "    x_gradient = 2*x_current\n",
    "    y_gradient = 2*y_current\n",
    "    \n",
    "    new_x = x_current - learningRate*x_gradient\n",
    "    new_y = y_current - learningRate*y_gradient\n",
    "    \n",
    "    ax.quiver(x_current, y_current, (fun(x_current, y_current)) ,\n",
    "              - (learningRate * x_gradient), - (learningRate * y_gradient), \n",
    "              (-(fun(x_current,y_current)-fun(new_x,new_y)))) \n",
    "    \n",
    "    return [new_x, new_y]\n",
    "\n",
    "def gradient_descent_runner_2d(starting_x, starting_y, learning_rate, num_iterations):\n",
    "    x = starting_x\n",
    "    y = starting_y\n",
    "    for i in range(num_iterations):\n",
    "        x, y = step_gradient_2d(x, y, learning_rate)\n",
    "        #print(x, y)\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "learning_rate = 0.9\n",
    "initial_x = 0 # initial y-intercept guess\n",
    "initial_y = 5 # initial slope guess\n",
    "num_iterations = 10\n",
    "[x, y] = gradient_descent_runner_2d(initial_x, initial_y, learning_rate, num_iterations)\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "plt.plot([initial_x],[initial_y],[fun(initial_x,initial_y)],\"ok\")\n",
    "plt.show()\n"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "Wykonaj analogiczne zadanie ale z:\n",
    "  * initial_x = 5 \n",
    "  * initial_y = 0 \n",
    "  * num_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:33.898272Z",
     "start_time": "2024-05-19T18:38:33.523798Z"
    }
   },
   "source": [
    "plt.close('all')\n",
    "\n",
    "fun = lambda x,y: 4*x**2+y**2\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-7, 7, 0.25)\n",
    "Y = np.arange(-7, 7, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = fun(X, Y)\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0.01, antialiased=True, alpha=0.3)\n",
    "\n",
    "learning_rate = 0.9\n",
    "initial_x = 5 # initial y-intercept guess\n",
    "initial_y = 0 # initial slope guess\n",
    "num_iterations = 10\n",
    "[x, y] = gradient_descent_runner_2d(initial_x, initial_y, learning_rate, num_iterations)\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "plt.plot([initial_x],[initial_y],[fun(initial_x,initial_y)],\"ok\")\n",
    "plt.show()"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie\n",
    "Wykonaj analogiczne zadanie ale z obrazkiem 2d\n",
    "\n",
    "$$\n",
    "f(x,y)=x^2-2x+y^2,\n",
    "$$ \n",
    "\n",
    "oraz\n",
    "\n",
    "$$\n",
    "f(x,y)=4*x^2-2x+y^2,\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:35.269609Z",
     "start_time": "2024-05-19T18:38:33.899833Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chi2 = lambda x,y: x**2-2*x+y**2\n",
    "\n",
    "x = np.arange(-10,10,0.02)\n",
    "y = np.arange(-10,10,0.02)\n",
    "\n",
    "X,Y= np.meshgrid(x,y)\n",
    "\n",
    "Z = chi2(X,Y)\n",
    "\n",
    "plt.figure()\n",
    "CS = plt.contour(X,Y,Z)\n",
    "\n",
    "plt.plot([5],[5],\"o\")\n",
    "\n",
    "#####################################\n",
    "\n",
    "def step_gradient_2d(x_current, y_current, learningRate):\n",
    "    x_gradient = 2*x_current-2\n",
    "    y_gradient = 2*y_current\n",
    "    \n",
    "    new_x = x_current - (learningRate * x_gradient)\n",
    "    new_y = y_current - (learningRate * y_gradient)\n",
    "    \n",
    "    plt.arrow(x_current, y_current, - (learningRate * x_gradient), - (learningRate * y_gradient), head_width=0.05, head_length=0.5,ec=\"red\")\n",
    "    \n",
    "    return [new_x, new_y]\n",
    "def gradient_descent_runner_2d(starting_x, starting_y, learning_rate, num_iterations):\n",
    "    x = starting_x\n",
    "    y = starting_y\n",
    "    for i in range(num_iterations):\n",
    "        x, y = step_gradient_2d(x, y, learning_rate)\n",
    "        #print(x, y)\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "learning_rate = 0.3\n",
    "initial_x = 0 # initial y-intercept guess\n",
    "initial_y = 5 # initial slope guess\n",
    "num_iterations = 1000\n",
    "[x, y] = gradient_descent_runner_2d(initial_x, initial_y, learning_rate, num_iterations)\n",
    "\n",
    "\n",
    "#####################################\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:36.317882Z",
     "start_time": "2024-05-19T18:38:35.270855Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chi3 = lambda x,y: 4*x**2 - 2*x+y**2\n",
    "\n",
    "x = np.arange(-10,10,0.02)\n",
    "y = np.arange(-10,10,0.02)\n",
    "\n",
    "X,Y= np.meshgrid(x,y)\n",
    "\n",
    "Z = chi3(X,Y)\n",
    "\n",
    "plt.figure()\n",
    "CS = plt.contour(X,Y,Z)\n",
    "\n",
    "plt.plot([5],[5],\"o\")\n",
    "\n",
    "learning_rate = 0.1\n",
    "initial_x = 5 # initial y-intercept guess\n",
    "initial_y = 5 # initial slope guess\n",
    "num_iterations = 1000\n",
    "[x, y] = gradient_descent_runner_2d(initial_x, initial_y, learning_rate, num_iterations)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napisz (od podstaw) algorytm znajdowania minimum metodą gradientową.\n",
    "Zaprezentuj jego działanie na przykładzie funkcji $f(x)=x^2-y^2$, startując z punktu $x=5$ oraz $x=1$. Zilustruj całą sytuacje oznaczając na wykresie 5 pierwszych iteracji.\n",
    "\n",
    "Wykonaj rysunek:\n",
    "  \n",
    "  * 2D conture plot\n",
    "  * 3D \n",
    "  \n",
    "Co się stanie gdy zaczniemy z punktu $x=5$ oraz $x=0$? "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:36.733231Z",
     "start_time": "2024-05-19T18:38:36.319054Z"
    }
   },
   "source": [
    "fun = lambda x,y: x**2 - y**2\n",
    "\n",
    "def step_gradient_2d(x_current, y_current, learningRate):\n",
    "    x_gradient = 2*x_current\n",
    "    y_gradient = 2*y_current\n",
    "    \n",
    "    new_x = x_current - learningRate*x_gradient\n",
    "    new_y = y_current - learningRate*y_gradient\n",
    "    \n",
    "    ax.quiver(x_current, y_current, (fun(x_current, y_current)) ,\n",
    "              - (learningRate * x_gradient), - (learningRate * y_gradient), \n",
    "              (-(fun(x_current,y_current)-fun(new_x,new_y)))) \n",
    "    \n",
    "    return [new_x, new_y]\n",
    "\n",
    "def gradient_descent_runner_2d(starting_x, starting_y, learning_rate, num_iterations):\n",
    "    x = starting_x\n",
    "    y = starting_y\n",
    "    for i in range(num_iterations):\n",
    "        x, y = step_gradient_2d(x, y, learning_rate)\n",
    "        #print(x, y)\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-7, 7, 0.25)\n",
    "Y = np.arange(-7, 7, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = fun(X, Y)\n",
    "\n",
    "# Define the parameters\n",
    "learning_rate = 0.9\n",
    "num_iterations = 10\n",
    "\n",
    "starting_points = [(5, 0), (5, 1)]\n",
    "for starting_x, starting_y in starting_points:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, linewidth=0.01, antialiased=True, alpha=0.3)\n",
    "    [x, y] = gradient_descent_runner_2d(starting_x, starting_y, learning_rate, num_iterations)\n",
    "    ax.plot([starting_x],[starting_y],[fun(starting_x,starting_y)],\"ok\")\n",
    "    ax.set_title(f'Starting point: ({starting_x}, {starting_y})')\n",
    "    plt.show()\n"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:37.230640Z",
     "start_time": "2024-05-19T18:38:36.734443Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chi2 = lambda x,y: x**2-y**2\n",
    "\n",
    "def step_gradient_2d(x_current, y_current, learningRate):\n",
    "    x_gradient = 2*x_current-2\n",
    "    y_gradient = 2*y_current\n",
    "    new_x = x_current - (learningRate * x_gradient)\n",
    "    new_y = y_current - (learningRate * y_gradient)\n",
    "    return [new_x, new_y]\n",
    "\n",
    "def gradient_descent_runner_2d(starting_x, starting_y, learning_rate, num_iterations):\n",
    "    x = starting_x\n",
    "    y = starting_y\n",
    "    for i in range(num_iterations):\n",
    "        x, y = step_gradient_2d(x, y, learning_rate)\n",
    "    return [x, y]\n",
    "\n",
    "# Make data.\n",
    "x = np.arange(-10,10,0.02)\n",
    "y = np.arange(-10,10,0.02)\n",
    "X,Y= np.meshgrid(x,y)\n",
    "Z = chi2(X,Y)\n",
    "\n",
    "# Define the parameters\n",
    "learning_rate = 0.1\n",
    "num_iterations = 1000\n",
    "\n",
    "# Run the gradient descent algorithm for each starting point\n",
    "starting_points = [(5, 0), (5, 1)]\n",
    "for starting_x, starting_y in starting_points:\n",
    "    plt.figure()\n",
    "    CS = plt.contour(X,Y,Z)\n",
    "    plt.plot([starting_x],[starting_y],\"o\")\n",
    "    [x, y] = gradient_descent_runner_2d(starting_x, starting_y, learning_rate, num_iterations)\n",
    "    plt.title(f'Starting point: ({starting_x}, {starting_y})')\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ],
   "execution_count": 32,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
